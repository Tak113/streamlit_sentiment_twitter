{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecc0d6a-2a0f-4233-9c73-09f9ca323a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "from requests_oauthlib import OAuth1Session\n",
    "import json\n",
    "import datetime, time, sys\n",
    "from abc import ABCMeta, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8b97e4-5310-4c30-909d-0827799f4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter api\n",
    "CK = 'YSTRJOf78h4O3Nh3eLe750eXh' # API\n",
    "CS = 'zXj1XtWrO1DC8xeE9c1LBpq6F7wo5Wp2YGeBU0dHjq6cfdTbjm' # API Secret\n",
    "AT = '1318425889600802817-xwztBCt7L07WTaffcCXC2N1P5XhVPQ' # Access Token\n",
    "AS = '1Lgxl4e6fJN1YGJuCcYg1aUvhDSJZ2zyKmJHWnRTSV4tx' # Access Token Secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917f441-a9db-4eff-b7a2-2ce5dd329546",
   "metadata": {},
   "source": [
    "## Scrape function/class setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8132ca2c-7ee9-458d-9fdf-e96473c2b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Getter Main Class\n",
    "class TweetsGetter(object):\n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = OAuth1Session(CK, CS, AT, AS) # connect to twitter API\n",
    "    \n",
    "    @abstractmethod\n",
    "    def specifyUrlAndParams(self, keyword):\n",
    "        '''\n",
    "        Return URL and Parameters\n",
    "        '''\n",
    "    \n",
    "    @abstractmethod\n",
    "    def pickupTweet(self, res_text, includeRetweet):\n",
    "        '''\n",
    "        pull tweets from res_text, convert to array set and return\n",
    "        '''\n",
    "    \n",
    "    @abstractmethod\n",
    "    def getLimitContext(self, res_text):\n",
    "        '''\n",
    "        get # of limits info when start\n",
    "        '''\n",
    "    \n",
    "    def collect(self, total = -1, onlyText = False, includeRetweet = False):\n",
    "        '''\n",
    "        start to get tweets\n",
    "        '''\n",
    "        \n",
    "        # check n of limites\n",
    "        self.checkLimit()\n",
    "        \n",
    "        # URL, parameter\n",
    "        url, params = self.specifyUrlAndParams()\n",
    "        # include_rts is paramter for statuses/user_timeline, can't use forsearch/tweets\n",
    "        params['include_rts'] = str(includeRetweet).lower()\n",
    "        \n",
    "        # getting tweets\n",
    "        cnt = 0\n",
    "        unavailableCnt = 0\n",
    "        while True:\n",
    "            res = self.session.get(url, params = params)\n",
    "            if res.status_code == 503:\n",
    "                # 503 : Service Unavailable\n",
    "                if unavailableCnt > 10:\n",
    "                    raise Exception('Twitter API error %d' % res.status_code)\n",
    "                \n",
    "                unavailableCnt += 1\n",
    "                print ('Service Unavailable 503')\n",
    "                self.waitUntilReset(time.mktime(datetime.datetime.now().timetuple()) + 30)\n",
    "                continue\n",
    "            \n",
    "            unavailableCnt = 0\n",
    "            \n",
    "            if res.status_code != 200:\n",
    "                raise Exception('Twitter API erorr %d' % res.status_code)\n",
    "                \n",
    "            tweets = self.pickupTweet(json.loads(res.text))\n",
    "            if len(tweets) == 0:\n",
    "                # watned len(tweets) !=['count'], but seems count is maximum and can't use for classification\n",
    "                # so ' == 0'\n",
    "                # ref : https://dev.twitter.com/discussions/7513\n",
    "                break\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                if(('retweeted_status' in tweet) and (includeRetweet is False)):\n",
    "                    pass\n",
    "                else:\n",
    "                    if onlyText is True:\n",
    "                        yield tweet['text']\n",
    "                    else:\n",
    "                        yield tweet\n",
    "                        \n",
    "                    cnt += 1\n",
    "                    if cnt % 100 == 0:\n",
    "                        print('%d ' % cnt)\n",
    "                    \n",
    "                    if total > 0 and cnt >= total:\n",
    "                        return\n",
    "            \n",
    "            params['max_id'] = tweet['id'] - 1\n",
    "            \n",
    "            # confirm limitation\n",
    "            # sometimes X-$Rate-Limit-Remaining is not included, so check\n",
    "            if ('X-Rate-Limit_Remaining' in res.headers and 'X-Rate-Limit-Reset' in res.headers):\n",
    "                if (int(res.headers['X-Rate-Limit-Remaining']) == 0):\n",
    "                    self.waitUntilReset(int(res.headers['X-Rate-Limit-Reset']))\n",
    "                    self.checkLimit()\n",
    "                else:\n",
    "                    print('not found - X-Rate-Limit-Remaining or X-Rate-Limit-Reset')\n",
    "                    self.checkLimit()\n",
    "            \n",
    "    def checkLimit(self):\n",
    "        '''\n",
    "        ask limitation and wait until accessible\n",
    "        '''\n",
    "        unavailableCnt = 0\n",
    "        while True:\n",
    "            url = \"https://api.twitter.com/1.1/application/rate_limit_status.json\"\n",
    "            res = self.session.get(url)\n",
    "\n",
    "            if res.status_code == 503:\n",
    "                # 503 : Service Unavailable\n",
    "                if unavailableCnt > 10:\n",
    "                    raise Exception('Twitter API error %d' % res.status_code)\n",
    "\n",
    "                unavailableCnt += 1\n",
    "                print ('Service Unavailable 503')\n",
    "                self.waitUntilReset(time.mktime(datetime.datetime.now().timetuple()) + 30)\n",
    "                continue\n",
    "\n",
    "            unavailableCnt = 0\n",
    "\n",
    "            if res.status_code != 200:\n",
    "                raise Exception('Twitter API error %d' % res.status_code)\n",
    "\n",
    "            remaining, reset = self.getLimitContext(json.loads(res.text))\n",
    "            if (remaining == 0):\n",
    "                self.waitUntilReset(reset)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    def waitUntilReset(self, reset):\n",
    "        '''\n",
    "        sleep until reset time\n",
    "        '''\n",
    "        seconds = reset - time.mktime(datetime.datetime.now().timetuple())\n",
    "        seconds = max(seconds, 0)\n",
    "        print ('\\n     =====================')\n",
    "        print ('     == Exceeding Rate Limit for the API endpoint ==' % seconds)\n",
    "        print ('     == waiting %d sec ==' % seconds)\n",
    "        print ('     =====================')\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(seconds + 10)  # add +10 sec just in case\n",
    "    \n",
    "    @staticmethod\n",
    "    def bySearch(keyword):\n",
    "        return TweetsGetterBySearch(keyword)\n",
    "    \n",
    "    @staticmethod\n",
    "    def byUser(screen_name):\n",
    "        return TweetsGetterByUser(screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd8b2d0-3964-42f9-b493-3251b0809eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsGetterBySearch(TweetsGetter):\n",
    "    '''\n",
    "    get tweets by keyward\n",
    "    '''\n",
    "    def __init__(self, keyword):\n",
    "        super(TweetsGetterBySearch, self).__init__()\n",
    "        self.keyword = keyword\n",
    "    \n",
    "    def specifyUrlAndParams(self):\n",
    "        '''\n",
    "        return URL and parameter\n",
    "        '''\n",
    "        url = 'https://api.twitter.com/1.1/search/tweets.json'\n",
    "        params = {'q':self.keyword, 'count':100}\n",
    "        return url, params\n",
    "    \n",
    "    def pickupTweet(self, res_text):\n",
    "        '''\n",
    "        pull tweets from res_text and convert to array and return\n",
    "        '''\n",
    "        results = []\n",
    "        for tweet in res_text['statuses']:\n",
    "            results.append(tweet)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def getLimitContext(self, res_text):\n",
    "        '''\n",
    "        get limitation info when start\n",
    "        '''\n",
    "        remaining = res_text['resources']['search']['/search/tweets']['remaining']\n",
    "        reset     = res_text['resources']['search']['/search/tweets']['reset']\n",
    "        \n",
    "        return int(remaining), int(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b0a31c-2998-4bb2-a88f-0250ed6f5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsGetterByUser(TweetsGetter):\n",
    "    '''\n",
    "    get tweets by selecting user. not workign now, needs overhaul\n",
    "    '''\n",
    "    def __init__(self, screen_name):\n",
    "        super(TweetsGetterByUser, self).__init__()\n",
    "        self.screen_name = screen_name\n",
    "    \n",
    "    def specifyUrlAndParams(self):\n",
    "        '''\n",
    "        pull tweets from res_text and convert array and return\n",
    "        '''\n",
    "        results = []\n",
    "        for tweet in res_text:\n",
    "            results.append(tweet)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def getLimitContext(self, res_text):\n",
    "        '''\n",
    "        get limitation info when start\n",
    "        '''\n",
    "        remaining = res_text['resources']['statuses']['/statuses/user_timeline']['remaining']\n",
    "        reset     = res_text['resources']['statuses']['/statuses/user_timeline']['reset']\n",
    "\n",
    "        return int(remaining), int(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8faa879c-439a-4af6-9141-50edacdfeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # get tweets by keyword\n",
    "    getter = TweetsGetter.bySearch(u'datascience')\n",
    "    \n",
    "    # get tweets by user (screen_name)\n",
    "    #getter = TweetsGetter.byUser('@realDonaldTrump')\n",
    "    \n",
    "    list_text = []\n",
    "    list_id = []\n",
    "    list_user_screenname = []\n",
    "    list_created_at = []\n",
    "    \n",
    "    for tweet in getter.collect(total = 10): # total is number of tweets to get\n",
    "        list_text.append(tweet['text'])\n",
    "        list_id.append(tweet['id'])\n",
    "        list_user_screenname.append(tweet['user']['screen_name'])\n",
    "        list_created_at.append(tweet['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e029a-75d0-4f9b-9f19-6f59ee24812c",
   "metadata": {},
   "source": [
    "## Output scraping results to dataframe\n",
    "There is a rate limitation for each API endpoint twitter provided. My API endpoint limites around 5000/hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b5bd00a-850c-4837-a257-f0224204f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text                   id  \\\n",
      "0  #AI - build it or buy it? https://t.co/n4DzGIp...  1387440722425434114   \n",
      "1  Congrats to the coolest data science and machi...  1387440219272716290   \n",
      "2  Tu es data scientist ou développeur backend ? ...  1387440081582137350   \n",
      "3  Business Standard declares #HCL as the Company...  1387439753231020036   \n",
      "4  Click the #transcription option to get all you...  1387439726618087427   \n",
      "5  Adi Tatarko Honey Pot Befez \\n#best #Custom #H...  1387439720532226051   \n",
      "6  RSNA: Researchers Use Artificial Intelligence ...  1387439712009400320   \n",
      "7  We just completed ses. #4 of the @creativedlab...  1387439670003372032   \n",
      "8  VB &gt; Gartner says low-code, RPA, and AI dri...  1387439571164610563   \n",
      "9  Keep up-to-date with the latest oncology, rat ...  1387438984150888454   \n",
      "\n",
      "              user                      created_at  \n",
      "0       tweetgrady  Wed Apr 28 16:17:00 +0000 2021  \n",
      "1              CRN  Wed Apr 28 16:15:00 +0000 2021  \n",
      "2     pa_chevalier  Wed Apr 28 16:14:27 +0000 2021  \n",
      "3       Tanguy_lrx  Wed Apr 28 16:13:09 +0000 2021  \n",
      "4         TalkShoe  Wed Apr 28 16:13:02 +0000 2021  \n",
      "5  Little_Redstone  Wed Apr 28 16:13:01 +0000 2021  \n",
      "6       nordicinst  Wed Apr 28 16:12:59 +0000 2021  \n",
      "7  DSE_DataScience  Wed Apr 28 16:12:49 +0000 2021  \n",
      "8      BigDataLove  Wed Apr 28 16:12:25 +0000 2021  \n",
      "9      HeraBioLabs  Wed Apr 28 16:10:05 +0000 2021  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['text', 'id', 'user', 'created_at'])\n",
    "df_new = df.assign(text=list_text, id=list_id, user=list_user_screenname, created_at=list_created_at)\n",
    "\n",
    "print(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4711e1e-9db3-443a-81c1-aaecd60863ce",
   "metadata": {},
   "source": [
    "## Apply pos/neg classification : Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aedfba9-5192-47b8-b305-901b546ce813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NLP libraries\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "global tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12c777f2-3628-4ebd-97c9-b22a52109a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 09:18:52,077 loading file /Users/tak/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "def load_flair():\n",
    "\treturn TextClassifier.load('en-sentiment')\n",
    "\n",
    "tagger = load_flair()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f3ad2c-c7ca-4d8a-8487-ea30f1d2e435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"I love tokyo\"   [− Tokens: 3  − Sentence-Labels: {'label': [POSITIVE (0.9945)]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick manual test for flair NLP\n",
    "s = Sentence('I love tokyo')\n",
    "tagger.predict(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf7d6648-d2d2-4591-ad77-e7467bdd7c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"# AI - build it or buy it ? https :// t.co / n4DzGIpHyG # DataScience # ML\"   [− Tokens: 18  − Sentence-Labels: {'label': [POSITIVE (0.8868)]}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick manual test for flair NLP apply for data frame\n",
    "s = Sentence(df_new['text'][0])\n",
    "tagger.predict(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d996e7c9-2eff-4d66-9347-da7e769572d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8867866396903992"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.labels[0].score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04be3c-8603-48ee-a534-10c4fef95613",
   "metadata": {},
   "source": [
    "## Apply pos/neg classification : Automate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c36e69ad-6a69-41b6-bb00-fde6a3ff0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty dataframe\n",
    "tweet_data = pd.DataFrame({\n",
    "    'tweet': [],\n",
    "    'predicted-sentiment-value': []\n",
    "    'predicted-sentiment-score': []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0951643-b72d-4e31-9122-04a76d5ad771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of positive vs negative tweets\n",
    "pos_vs_neg = {'POSITIVE':0, 'NEGATIVE': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54feab6f-a1be-4656-a729-d82aef8aa5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data for each tweet\n",
    "for tweet in list_text:\n",
    "    # skip iteration if tweet is empty\n",
    "    if tweet in ('',' '):\n",
    "        continue\n",
    "    # make predictions\n",
    "    sentence = Sentence(tweet)\n",
    "    tagger.predict(sentence)\n",
    "    # keep track of positive vs negative tweets\n",
    "    pos_vs_neg[sentence.labels[0].value] += 1 #value is either POSITIVE or NEGATIVE\n",
    "    # append new data\n",
    "    tweet_data = tweet_data.append({'tweet': tweet,\n",
    "                                    'predicted-sentiment-value': sentence.labels[0].value,\n",
    "                                   'predicted-sentiment-score': sentence.labels[0].score}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a78a8688-7dab-49e0-9863-418f4d795f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>predicted-sentiment</th>\n",
       "      <th>predicted-sentiment-score</th>\n",
       "      <th>predicted-sentiment-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#AI - build it or buy it? https://t.co/n4DzGIp...</td>\n",
       "      <td>0.886787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Congrats to the coolest data science and machi...</td>\n",
       "      <td>0.977923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tu es data scientist ou développeur backend ? ...</td>\n",
       "      <td>0.925735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Standard declares #HCL as the Company...</td>\n",
       "      <td>0.992099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Click the #transcription option to get all you...</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adi Tatarko Honey Pot Befez \\n#best #Custom #H...</td>\n",
       "      <td>0.994835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RSNA: Researchers Use Artificial Intelligence ...</td>\n",
       "      <td>0.878480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We just completed ses. #4 of the @creativedlab...</td>\n",
       "      <td>0.982536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VB &amp;gt; Gartner says low-code, RPA, and AI dri...</td>\n",
       "      <td>0.571626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Keep up-to-date with the latest oncology, rat ...</td>\n",
       "      <td>0.959759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#AI - build it or buy it? https://t.co/n4DzGIp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.886787</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Congrats to the coolest data science and machi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977923</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tu es data scientist ou développeur backend ? ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925735</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Business Standard declares #HCL as the Company...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992099</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Click the #transcription option to get all you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adi Tatarko Honey Pot Befez \\n#best #Custom #H...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994835</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RSNA: Researchers Use Artificial Intelligence ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878480</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>We just completed ses. #4 of the @creativedlab...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982536</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VB &amp;gt; Gartner says low-code, RPA, and AI dri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571626</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Keep up-to-date with the latest oncology, rat ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959759</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  predicted-sentiment  \\\n",
       "0   #AI - build it or buy it? https://t.co/n4DzGIp...             0.886787   \n",
       "1   Congrats to the coolest data science and machi...             0.977923   \n",
       "2   Tu es data scientist ou développeur backend ? ...             0.925735   \n",
       "3   Business Standard declares #HCL as the Company...             0.992099   \n",
       "4   Click the #transcription option to get all you...             0.999970   \n",
       "5   Adi Tatarko Honey Pot Befez \\n#best #Custom #H...             0.994835   \n",
       "6   RSNA: Researchers Use Artificial Intelligence ...             0.878480   \n",
       "7   We just completed ses. #4 of the @creativedlab...             0.982536   \n",
       "8   VB &gt; Gartner says low-code, RPA, and AI dri...             0.571626   \n",
       "9   Keep up-to-date with the latest oncology, rat ...             0.959759   \n",
       "10  #AI - build it or buy it? https://t.co/n4DzGIp...                  NaN   \n",
       "11  Congrats to the coolest data science and machi...                  NaN   \n",
       "12  Tu es data scientist ou développeur backend ? ...                  NaN   \n",
       "13  Business Standard declares #HCL as the Company...                  NaN   \n",
       "14  Click the #transcription option to get all you...                  NaN   \n",
       "15  Adi Tatarko Honey Pot Befez \\n#best #Custom #H...                  NaN   \n",
       "16  RSNA: Researchers Use Artificial Intelligence ...                  NaN   \n",
       "17  We just completed ses. #4 of the @creativedlab...                  NaN   \n",
       "18  VB &gt; Gartner says low-code, RPA, and AI dri...                  NaN   \n",
       "19  Keep up-to-date with the latest oncology, rat ...                  NaN   \n",
       "\n",
       "    predicted-sentiment-score predicted-sentiment-value  \n",
       "0                         NaN                       NaN  \n",
       "1                         NaN                       NaN  \n",
       "2                         NaN                       NaN  \n",
       "3                         NaN                       NaN  \n",
       "4                         NaN                       NaN  \n",
       "5                         NaN                       NaN  \n",
       "6                         NaN                       NaN  \n",
       "7                         NaN                       NaN  \n",
       "8                         NaN                       NaN  \n",
       "9                         NaN                       NaN  \n",
       "10                   0.886787                  POSITIVE  \n",
       "11                   0.977923                  POSITIVE  \n",
       "12                   0.925735                  POSITIVE  \n",
       "13                   0.992099                  POSITIVE  \n",
       "14                   0.999970                  NEGATIVE  \n",
       "15                   0.994835                  POSITIVE  \n",
       "16                   0.878480                  POSITIVE  \n",
       "17                   0.982536                  POSITIVE  \n",
       "18                   0.571626                  POSITIVE  \n",
       "19                   0.959759                  POSITIVE  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see prediction against each tweets\n",
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32176060-eb9e-45ef-9891-29f19227ec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POSITIVE': 19, 'NEGATIVE': 2}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see pos_vs_neg\n",
    "pos_vs_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1bc88f9d-f1d9-4c36-ae96-1229b57c1701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get positive rate\n",
    "pos_rate = round(pos_vs_neg['POSITIVE']/(pos_vs_neg['NEGATIVE']+pos_vs_neg['POSITIVE'])*100,1)\n",
    "pos_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
